{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "509a32f5",
   "metadata": {},
   "source": [
    "# Graph Classification Demo\n",
    "\n",
    "Demo classifying the work status of day-long schedules using node lables (activity and zone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a009bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from torch import stack, cat, nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "from ntsx.nx_to_torch import nx_to_torch_geo\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_mean_pool, GCNConv\n",
    "\n",
    "from ntsx import graph_ops, nts_to_nx\n",
    "from ntsx import read_nts\n",
    "from ntsx.encoders.trip_encoder import TripEncoder\n",
    "from ntsx.encoders.table_encoder import TableTokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0c27ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dummy data (synthesised from UK NTS)\n",
    "\n",
    "dir = Path(\"data/dummyNTS/\")\n",
    "trips_path = dir / \"trips.tab\"\n",
    "attributes_path = dir / \"individuals.tab\"\n",
    "hhs_path = dir / \"households.tab\"\n",
    "\n",
    "years = [2021]\n",
    "\n",
    "write_dir = Path(\"tmp\")\n",
    "write_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e2548b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIDs in people and households do not match, attempting to fix...\n",
      "Fixed: People 6 -> 7, HHs 5 -> 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unemployed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unemployed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unemployed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>employed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    work_status\n",
       "iid            \n",
       "1    unemployed\n",
       "2      employed\n",
       "3    unemployed\n",
       "4    unemployed\n",
       "5      employed"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>iid</th>\n",
       "      <th>hid</th>\n",
       "      <th>seq</th>\n",
       "      <th>mode</th>\n",
       "      <th>oact</th>\n",
       "      <th>dact</th>\n",
       "      <th>freq</th>\n",
       "      <th>tst</th>\n",
       "      <th>tet</th>\n",
       "      <th>ozone</th>\n",
       "      <th>dzone</th>\n",
       "      <th>did</th>\n",
       "      <th>pid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>car</td>\n",
       "      <td>home</td>\n",
       "      <td>social</td>\n",
       "      <td>0.989618</td>\n",
       "      <td>675</td>\n",
       "      <td>683</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>car</td>\n",
       "      <td>social</td>\n",
       "      <td>other</td>\n",
       "      <td>1.002945</td>\n",
       "      <td>720</td>\n",
       "      <td>735</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>car</td>\n",
       "      <td>other</td>\n",
       "      <td>social</td>\n",
       "      <td>0.989618</td>\n",
       "      <td>770</td>\n",
       "      <td>780</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>taxi</td>\n",
       "      <td>social</td>\n",
       "      <td>home</td>\n",
       "      <td>0.989618</td>\n",
       "      <td>1110</td>\n",
       "      <td>1130</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>car</td>\n",
       "      <td>home</td>\n",
       "      <td>social</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>760</td>\n",
       "      <td>770</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tid  year  day  iid  hid  seq  mode    oact    dact      freq   tst   tet  \\\n",
       "0    1  2021    2    1    1    1   car    home  social  0.989618   675   683   \n",
       "1    2  2021    2    1    1    2   car  social   other  1.002945   720   735   \n",
       "2    3  2021    2    1    1    3   car   other  social  0.989618   770   780   \n",
       "3    4  2021    2    1    1    4  taxi  social    home  0.989618  1110  1130   \n",
       "4    5  2021    3    1    1    1   car    home  social  0.999891   760   770   \n",
       "\n",
       "   ozone  dzone  did  pid  \n",
       "0      7      7    0  1_1  \n",
       "1      7      7    0  1_1  \n",
       "2      7      7    0  1_1  \n",
       "3      7      7    0  1_1  \n",
       "4      7      7    1  1_1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data from disk\n",
    "trips, labels = read_nts.load_nts(trips_path, attributes_path, hhs_path, years=years)\n",
    "\n",
    "# assign human readable values to the labels\n",
    "labels = read_nts.label_mapping(labels)\n",
    "\n",
    "# initaite the encoders\n",
    "label_encoder = TableTokeniser(labels, verbose=False)\n",
    "trip_encoder = TripEncoder(trips)\n",
    "\n",
    "display(labels[[\"work_status\"]].head())\n",
    "display(trips.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57816978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity mapping: {'education': 0, 'escort': 1, 'home': 2, 'hotel': 3, 'medical': 4, 'other': 5, 'shop': 6, 'social': 7, 'work': 8}\n"
     ]
    }
   ],
   "source": [
    "# first encode the trips and lables tables\n",
    "trips_encoded = trip_encoder.encode_trips_table(trips)\n",
    "print(f\"Activity mapping: {trip_encoder.encoders[\"oact\"].mapping}\")\n",
    "\n",
    "labels_encoded = label_encoder.encode_table(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f01361c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: overwriting act from 2 to 0\n",
      "DataBatch(edge_index=[2, 59], act=[53], location=[53], duration=[59], day=[16], tst=[59], tet=[59], travel=[59], iid=[16], age=[16], gender=[16], ethnicity=[16], education=[16], license=[16], car_access=[16], work_status=[16], year=[16], area=[16], income=[16], hh_size=[16], hh_composition=[16], hh_children=[16], hh_cars=[16], hh_bikes=[16], hh_motorcycles=[16], num_nodes=53, batch=[53], ptr=[17])\n",
      "DataBatch(edge_index=[2, 68], act=[62], location=[62], duration=[68], day=[16], tst=[68], tet=[68], travel=[68], iid=[16], age=[16], gender=[16], ethnicity=[16], education=[16], license=[16], car_access=[16], work_status=[16], year=[16], area=[16], income=[16], hh_size=[16], hh_composition=[16], hh_children=[16], hh_cars=[16], hh_bikes=[16], hh_motorcycles=[16], num_nodes=62, batch=[62], ptr=[17])\n",
      "DataBatch(edge_index=[2, 22], act=[20], location=[20], duration=[22], day=[7], tst=[22], tet=[22], travel=[22], iid=[7], age=[7], gender=[7], ethnicity=[7], education=[7], license=[7], car_access=[7], work_status=[7], year=[7], area=[7], income=[7], hh_size=[7], hh_composition=[7], hh_children=[7], hh_cars=[7], hh_bikes=[7], hh_motorcycles=[7], num_nodes=20, batch=[20], ptr=[8])\n"
     ]
    }
   ],
   "source": [
    "# then build individuals and then days graphs from the trips table, note that we only merge on home (2)\n",
    "individuals = nts_to_nx.to_individuals_nx(trips_encoded, attribute_data=labels_encoded)\n",
    "days = []\n",
    "for ind in individuals:\n",
    "    g = graph_ops.anchor_activities(ind, [2])\n",
    "    g = graph_ops.merge_similar(g, duration_tolerance=0.2)\n",
    "\n",
    "    # now we can create a graph for each day\n",
    "    indiv_days = [d for _, d in graph_ops.iter_days(g, stop=None)]\n",
    "    days.extend(indiv_days)\n",
    "\n",
    "# now we can create a graph dataset\n",
    "dataset = nx_to_torch_geo(days)\n",
    "\n",
    "# finally we can create a dataloader\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "for data in loader:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784a5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 0.6982. Accuracy: 0.4375\n",
      "Epoch 0: Loss 0.6808. Accuracy: 0.4375\n",
      "Epoch 0: Loss 0.7134. Accuracy: 0.4286\n",
      "Epoch 1: Loss 0.5922. Accuracy: 0.6250\n",
      "Epoch 1: Loss 0.6982. Accuracy: 0.6250\n",
      "Epoch 1: Loss 0.6706. Accuracy: 0.4286\n",
      "Epoch 2: Loss 0.4851. Accuracy: 0.7500\n",
      "Epoch 2: Loss 0.6352. Accuracy: 0.6250\n",
      "Epoch 2: Loss 0.6362. Accuracy: 0.5714\n",
      "Epoch 3: Loss 0.6249. Accuracy: 0.7500\n",
      "Epoch 3: Loss 0.4433. Accuracy: 0.8750\n",
      "Epoch 3: Loss 0.7449. Accuracy: 0.4286\n",
      "Epoch 4: Loss 0.5545. Accuracy: 0.7500\n",
      "Epoch 4: Loss 0.4544. Accuracy: 0.8750\n",
      "Epoch 4: Loss 0.5864. Accuracy: 0.5714\n",
      "Epoch 5: Loss 0.5060. Accuracy: 0.8125\n",
      "Epoch 5: Loss 0.5349. Accuracy: 0.6875\n",
      "Epoch 5: Loss 0.5253. Accuracy: 0.7143\n",
      "Epoch 6: Loss 0.5190. Accuracy: 0.8125\n",
      "Epoch 6: Loss 0.5193. Accuracy: 0.7500\n",
      "Epoch 6: Loss 0.4131. Accuracy: 1.0000\n",
      "Epoch 7: Loss 0.4998. Accuracy: 0.6875\n",
      "Epoch 7: Loss 0.4739. Accuracy: 0.7500\n",
      "Epoch 7: Loss 0.4029. Accuracy: 0.8571\n",
      "Epoch 8: Loss 0.6202. Accuracy: 0.7500\n",
      "Epoch 8: Loss 0.4100. Accuracy: 0.7500\n",
      "Epoch 8: Loss 0.3754. Accuracy: 0.8571\n",
      "Epoch 9: Loss 0.4985. Accuracy: 0.7500\n",
      "Epoch 9: Loss 0.4048. Accuracy: 0.8750\n",
      "Epoch 9: Loss 0.4579. Accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "class MultiTokenEmbedSum(nn.Module):\n",
    "    def __init__(self, label_embed_sizes: list[int], hidden_size: int = 32):\n",
    "        \"\"\"Embed tokens and add them together.\"\"\"\n",
    "        super(MultiTokenEmbedSum, self).__init__()\n",
    "        self.embeds = nn.ModuleList(\n",
    "            [nn.Embedding(s, hidden_size) for s in label_embed_sizes]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return stack([embed(x[i]) for i, embed in enumerate(self.embeds)], dim=-1).sum(\n",
    "            dim=-1\n",
    "        )\n",
    "\n",
    "\n",
    "class GCNGraphLabeller(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, node_embed_sizes: list[int], target_size: int, hidden_size: int = 32\n",
    "    ):\n",
    "        \"\"\"A simple GNN model for graph classification.\"\"\"\n",
    "        super().__init__()\n",
    "        self.node_embed = MultiTokenEmbedSum(node_embed_sizes, hidden_size)\n",
    "        self.conv1 = GCNConv(hidden_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, target_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = [data.act, data.location]\n",
    "        edge_index, batch = data.edge_index, data.batch\n",
    "        x = self.node_embed(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "# train\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "node_embed_sizes = [\n",
    "    trip_encoder.embed_sizes()[\"oact\"],\n",
    "    trip_encoder.embed_sizes()[\"ozone\"],\n",
    "]\n",
    "target_size = label_encoder.embed_sizes()[\"work_status\"]\n",
    "\n",
    "model = GCNGraphLabeller(\n",
    "    node_embed_sizes=node_embed_sizes, target_size=target_size, hidden_size=32\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-3)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for data in loader:\n",
    "        data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        y = data.work_status\n",
    "        loss = F.nll_loss(out, y)\n",
    "        preds = out.argmax(dim=1)\n",
    "        correct = (preds == y).sum().item()\n",
    "        acc = correct / len(y)\n",
    "        print(f\"Epoch {epoch}: Loss {loss.item():.4f}. Accuracy: {acc:.4f}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f4b78d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 0.7630. Accuracy: 0.3125\n",
      "Epoch 0: Loss 0.7557. Accuracy: 0.4375\n",
      "Epoch 0: Loss 0.9625. Accuracy: 0.4286\n",
      "Epoch 1: Loss 0.6378. Accuracy: 0.6250\n",
      "Epoch 1: Loss 0.6666. Accuracy: 0.6875\n",
      "Epoch 1: Loss 0.7317. Accuracy: 0.4286\n",
      "Epoch 2: Loss 0.5808. Accuracy: 0.6875\n",
      "Epoch 2: Loss 0.6903. Accuracy: 0.6875\n",
      "Epoch 2: Loss 0.7519. Accuracy: 0.5714\n",
      "Epoch 3: Loss 0.6767. Accuracy: 0.5625\n",
      "Epoch 3: Loss 0.5379. Accuracy: 0.8125\n",
      "Epoch 3: Loss 0.5676. Accuracy: 0.7143\n",
      "Epoch 4: Loss 0.5060. Accuracy: 0.8125\n",
      "Epoch 4: Loss 0.5918. Accuracy: 0.6250\n",
      "Epoch 4: Loss 0.5716. Accuracy: 0.7143\n",
      "Epoch 5: Loss 0.5680. Accuracy: 0.7500\n",
      "Epoch 5: Loss 0.5130. Accuracy: 0.6875\n",
      "Epoch 5: Loss 0.5985. Accuracy: 0.7143\n",
      "Epoch 6: Loss 0.4837. Accuracy: 0.7500\n",
      "Epoch 6: Loss 0.5133. Accuracy: 0.6250\n",
      "Epoch 6: Loss 0.3809. Accuracy: 0.7143\n",
      "Epoch 7: Loss 0.6088. Accuracy: 0.6875\n",
      "Epoch 7: Loss 0.5137. Accuracy: 0.7500\n",
      "Epoch 7: Loss 0.2472. Accuracy: 0.8571\n",
      "Epoch 8: Loss 0.3487. Accuracy: 0.8125\n",
      "Epoch 8: Loss 0.4632. Accuracy: 0.8125\n",
      "Epoch 8: Loss 0.4040. Accuracy: 0.8571\n",
      "Epoch 9: Loss 0.3245. Accuracy: 0.9375\n",
      "Epoch 9: Loss 0.4654. Accuracy: 0.7500\n",
      "Epoch 9: Loss 0.2990. Accuracy: 0.8571\n"
     ]
    }
   ],
   "source": [
    "class GATGraphLabeller(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_embed_sizes: list[int],\n",
    "        edge_embed_sizes: list[int],\n",
    "        target_size: int,\n",
    "        hidden_size: int = 32,\n",
    "    ):\n",
    "        \"\"\"A simple GAT model for graph classification with edge and node attributes.\"\"\"\n",
    "        super().__init__()\n",
    "        self.node_embed = MultiTokenEmbedSum(node_embed_sizes, hidden_size)\n",
    "        self.edge_embed = MultiTokenEmbedSum(edge_embed_sizes, hidden_size)\n",
    "        self.conv1 = GATConv(hidden_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, target_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = [data.act, data.location]\n",
    "        x = self.node_embed(x)\n",
    "\n",
    "        x_edge_cont = stack([data.duration, data.tst, data.tet], dim=1)\n",
    "        x_edge_cat = [data.travel]\n",
    "        x_edge_cat = self.edge_embed(x_edge_cat)\n",
    "        x_edge = cat([x_edge_cat, x_edge_cont], dim=-1)\n",
    "\n",
    "        edge_index, batch = data.edge_index, data.batch\n",
    "\n",
    "        x = F.relu(x)\n",
    "        x = self.conv1(x, edge_index, x_edge)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "# train\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "node_embed_sizes = [\n",
    "    trip_encoder.embed_sizes()[\"oact\"],\n",
    "    trip_encoder.embed_sizes()[\"ozone\"],\n",
    "]\n",
    "edge_embed_sizes = [\n",
    "    trip_encoder.embed_sizes()[\"mode\"],\n",
    "]\n",
    "\n",
    "target_size = label_encoder.embed_sizes()[\"work_status\"]\n",
    "\n",
    "model = GATGraphLabeller(\n",
    "    node_embed_sizes=node_embed_sizes,\n",
    "    edge_embed_sizes=edge_embed_sizes,\n",
    "    target_size=target_size,\n",
    "    hidden_size=32,\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-3)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for data in loader:\n",
    "        data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        y = data.work_status\n",
    "        loss = F.nll_loss(out, y)\n",
    "        preds = out.argmax(dim=1)\n",
    "        correct = (preds == y).sum().item()\n",
    "        acc = correct / len(y)\n",
    "        print(f\"Epoch {epoch}: Loss {loss.item():.4f}. Accuracy: {acc:.4f}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntsx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
